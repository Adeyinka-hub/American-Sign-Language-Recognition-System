Development stage 2:
Searched for a better dataset and got one which is from Kaggle. This contains 24 classes of
alphabets(except J and Z) and special characters like space, delete, etc. Thus worked using only A,B,C.
The VGG16 architechture above is very complex. Hence wanted to experiment using less complex model.
Thus we trained an AlexNet(8 layers) from scratch on A,B,C classes. Achieved 80% accuracy.

